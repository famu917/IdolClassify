{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNを用いた坂道グループのメンバーの顔分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングをやりたくて、さわりとしてCNNを使った顔分類をやりました。  \n",
    "  \n",
    "乃木坂メンバーの顔をCNNで分類  \n",
    "https://qiita.com/nirs_kd56/items/bc78bf2c3164a6da1ded2    \n",
    "いろいろなサイトを見た結果、こちらのサイトが丁寧でわかりやすかったのでかなり参考にさせてもらいました。  \n",
    "  \n",
    "テーマが似たような感じなのはたまたま趣味が同じだったってことで、ここを変えたとこで差別化はできないと思ったのでこんなかんじになりました。  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境\n",
    "windows10　バージョン1903  \n",
    "Python 3.7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像のスクレイピング\n",
    "参考記事のスクレイピングは、chromeの仕様変更に伴って使えなくなっていたようなので、一から作り直しました。 \n",
    "  \n",
    "画像読み込みがページ切り替えで分かりやすかったYahoo画像検索を使用しました。  \n",
    "一度の実行で学習させたい人数分を一度にスクレイピングすることが出来ます。  \n",
    "  \n",
    "  \n",
    "検索結果画面のサムネイルを保存しているような形なので、画像サイズがかなり小さくなっていますが、一応使えます。\n",
    "``` python:image_collect.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import time\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "def main(search_word,maxcount):\n",
    "    # 検索URL準備\n",
    "    load_url=\"https://search.yahoo.co.jp/image/search?p=\"+search_word+\"&ei=UTF-8&b=\"\n",
    "\n",
    "\n",
    "    # 保存用フォルダを作る\n",
    "    data = Path(\"./data\")\n",
    "    data.mkdir(exist_ok=True)\n",
    "    out_folder=Path(\"data/\"+search_word)\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # すべてのhtmlタグを検索し、リンクを取得する\n",
    "    count=1\n",
    "\n",
    "    for i in range(1,maxcount,20):\n",
    "\n",
    "        # ページ切り替え\n",
    "        html = requests.get(load_url+str(i))\n",
    "        soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "        for element in soup.find_all(\"img\"):\n",
    "            src=element.get(\"src\")\n",
    "\n",
    "            # 絶対URLから画像を取得する\n",
    "            image_url=urllib.parse.urljoin(load_url,src)\n",
    "            imgdata=requests.get(image_url)\n",
    "\n",
    "            # URLから最後のファイル名を取り出して保存先のファイル名とつなげる\n",
    "            filename=str(count)+\".png\"\n",
    "            out_path=out_folder.joinpath(filename)\n",
    "\n",
    "            # 画像データをファイルに書き出す\n",
    "            with open(out_path,mode=\"wb\") as f:\n",
    "                f.write(imgdata.content)\n",
    "\n",
    "            # 枚数が十分だったらやめる\n",
    "            if maxcount<=count:\n",
    "                print(search_word+\"完了\")\n",
    "                break\n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "\n",
    "            # 0.2秒待つ\n",
    "            time.sleep(0.2)\n",
    "        print(str(count) + \"枚取得\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    member = []\n",
    "    num = int(input(\"人数\"))\n",
    "    for i in range(num):\n",
    "        member.append(input(\"検索ワード\"))\n",
    "    b = int(input(\"取得枚数\"))\n",
    "    for i in range(len(member)):\n",
    "        main(member[i], b)\n",
    "```\n",
    "  \n",
    "このコードを実行すると、標準入力が求められるので\n",
    "1. 人数\n",
    "2. 検索ワード(×人数)\n",
    "3. 取得枚数  \n",
    "![入力したときの感じ](./1.png)\n",
    "\n",
    "\n",
    "↑のように入力していきます。  \n",
    "  \n",
    "スクレイピングした画像はおなじ階層に以下のようなフォルダ構成で保存されます。\n",
    ">data/  \n",
    ">├ 検索ワード1/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  \n",
    ">  │　       \n",
    ">├ 検索ワード2/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  　       \n",
    ">...\n",
    "  \n",
    "600～700枚が限界みたいです。  \n",
    "実際200～300枚で十分学習はできるうえ、画像が多いとこの後の作業がだいぶきつくなるのでほどほどにしておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顔部分のトリミング\n",
    "参考記事のコードを少し変えました。  \n",
    "  \n",
    "  \n",
    "スクレイピングで作成されるフォルダ名に、検索ワードがそのまま使われるようになっているので、日本語のパスだとエラーが出るopencvの関数の対策などをしました。  \n",
    "  \n",
    "また、人数分コードを変えてトリミングするのも面倒なので、Tkinterを使用してGUIでフォルダを指定し、画像フォルダがまとめて保存されているフォルダ（今回はdataフォルダ）を選択すればすべてにトリミングが適用されるようにしました。  \n",
    "この変更はここから学習のコードまですべてにしています。\n",
    "  \n",
    "  \n",
    "このへんもパス関連で不具合が多く、Jupyterではうまく動かないというところが解決できませんでした。\n",
    "``` python:face_detect.py\n",
    "import glob\n",
    "import os\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "dataディレクトリから画像を読み込んで顔を切り取ってfaceディレクトリに保存.\n",
    "\"\"\"\n",
    "out_dir = \"./face\"\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "\n",
    "# パスに日本語が含まれる場合の対策\n",
    "# np.profileとcv2.imdecodeに分解した\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "#cv2.imencode + np.ndarray.tofile に分解\n",
    "def imwrite(filename, img, params=None):\n",
    "    try:\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        result, n = cv2.imencode(ext, img, params)\n",
    "\n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f:\n",
    "                n.tofile(f)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #各フォルダ指定\n",
    "    image_dir = dirdialog_clicked()\n",
    "    img_lists=os.listdir(path=image_dir)\n",
    "    out_dir=\".\"\n",
    "\n",
    "    for lists in range(len(img_lists)):\n",
    "        save_num = 0\n",
    "        # 元画像を取り出して顔部分を正方形で囲み、64×64pにリサイズ、別のファイルにどんどん入れてく\n",
    "        in_dir = image_dir +\"/\"+img_lists[lists] + \"/*.png\"\n",
    "        print(in_dir)\n",
    "        in_jpg = glob.glob(in_dir)\n",
    "        print(in_jpg)\n",
    "        os.makedirs(\"./face/\"+ os.path.basename(img_lists[lists]), exist_ok=True)\n",
    "        for num in in_jpg:\n",
    "            image = imread(num)\n",
    "            print(num)\n",
    "            if image is None:\n",
    "                print(\"Not open:\", num)\n",
    "                continue\n",
    "\n",
    "            image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_alt.xml\")\n",
    "            # 顔認識の実行\n",
    "            face_list = cascade.detectMultiScale(image_gs, scaleFactor=1.1, minNeighbors=2, minSize=(64, 64))\n",
    "            # 顔が１つ以上検出された時\n",
    "            if len(face_list) > 0:\n",
    "                for rect in face_list:\n",
    "                    x, y, width, height = rect\n",
    "                    image = image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]\n",
    "                    if image.shape[0] < 64:\n",
    "                        continue\n",
    "                    image = cv2.resize(image, (64, 64))\n",
    "                    # 保存\n",
    "                    fileName = \"./face/\"+ os.path.basename(img_lists[lists])+\"/\"+str(save_num)+\".png\"\n",
    "                    save_num+=1\n",
    "                    imwrite(str(fileName), image)\n",
    "                    print(fileName)\n",
    "                    print(img_lists[lists]+\"/\"+str(save_num)+\".pngを保存しました.\")\n",
    "            # 顔が検出されなかった時\n",
    "            else:\n",
    "                print(\"no face\")\n",
    "                continue\n",
    "            print(image.shape)\n",
    "\n",
    "\n",
    "``` \n",
    "スクレイピングした画像はおなじ階層に以下のようなフォルダ構成で保存されます。\n",
    ">face/  \n",
    ">├ 検索ワード1/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  \n",
    ">  │　       \n",
    ">├ 検索ワード2/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  　       \n",
    ">...\n",
    "  \n",
    "![顔認識したフォルダ](./2.png)\n",
    "こういった感じです。 \n",
    "  \n",
    "ここで手作業で、  \n",
    "\"分類したい人ではない画像\"、\"顔ではない部分の画像\"、\"学習に悪影響を及ぼしそうな画像\"  \n",
    "を消去していきます。（苦行）  \n",
    "  \n",
    "  \n",
    "700枚近くあった画像がこの時点で150～250枚程度まで減っています。  \n",
    "\n",
    "顔認識の時点でかなりの枚数が削られているので、スクレイピングの時点で高画質な画像を持ってこれるようにすれば改善するかもしれません。  \n",
    "それをするには画像それぞれのリンク先に飛ぶなりしてオリジナルの画像を持ってこる必要がありそうなので、いつか挑戦してみたいです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像仕分け\n",
    "テストデータと教師データのもととなる画像を分けるために画像を一定の割合でランダムにフォルダ分けするコードです。\n",
    "  \n",
    "  \n",
    "こちらも、日本語パス対策とGUIでのフォルダ指定ができるようにしています。\n",
    "  \n",
    "顔をトリミングした画像フォルダがあるフォルダを指定します。（今回はfaceフォルダ）\n",
    "``` python:deviede_test_train.py\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "os.makedirs(\"../test\", exist_ok=True)\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 画像フォルダ指定\n",
    "    image_dir = dirdialog_clicked()\n",
    "    img_lists = os.listdir(path=image_dir)\n",
    "    for lists in range(len(img_lists)):\n",
    "        in_dir = image_dir +\"/\"+img_lists[lists]+\"/*\"\n",
    "        in_jpg=glob.glob(in_dir)\n",
    "        img_file_name_list=os.listdir(image_dir +\"/\"+img_lists[lists]+\"/\")\n",
    "        #img_file_name_listをシャッフル、そのうち2割をtest_imageディテクトリに入れる\n",
    "        random.shuffle(in_jpg)\n",
    "        os.makedirs('./test/' + os.path.basename(img_lists[lists]), exist_ok=True)\n",
    "        for t in range(len(in_jpg)//5):\n",
    "            shutil.move(str(in_jpg[t]), \"./test/\"+\n",
    "``` \n",
    "これはデータセット全体を5分割し、うち1つをtestフォルダに送るものです。  \n",
    "成功すると、画像の8割がfaceフォルダに残り、2割がtestフォルダに送られています。\n",
    "![faceとtest](./3.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データの水増し\n",
    "ほかのコードと同じ変更に加えて、水増しのための画像加工に\"左右反転\"も加えました。  \n",
    "\n",
    "参考記事では、人の顔を左右反転するのもなあ、といった感じで反転はしないこととしていましたが、アイドルの自撮り画像は使用してるアプリの影響で左右反転されてるものも少なからずあるのと、教師データをめちゃくちゃに増やしてみたいという野望があったのでぼくは反転を取り入れることにしました。  \n",
    "      \n",
    "...と思ったのですが、回転させたオリジナルの画像、ぼかした画像、閾値処理した画像すべてに反転をかけて学習させると過学習を起こしてしまったので、オリジナルを反転させたモノだけを追加しました。\n",
    "\n",
    "なので、回転（3）×(オリジナル、ぼかし、閾値処理)＋反転で教師データが10倍になります。  \n",
    "  \n",
    "  \n",
    "コードを実行する際は、水増ししたい画像が入っているフォルダ（今回はface）を選択します。\n",
    "  \n",
    "``` python:inflation.py\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "faceディレクトリから画像を読み込んで回転、ぼかし、閾値処理をしてtrainディレクトリに保存する.\n",
    "\"\"\"\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "# パスに日本語が含まれる場合の対策\n",
    "# np.profileとcv2.imdecodeに分解した\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "#cv2.imencode + np.ndarray.tofile に分解\n",
    "def imwrite(filename, img, params=None):\n",
    "    try:\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        result, n = cv2.imencode(ext, img, params)\n",
    "\n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f:\n",
    "                n.tofile(f)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(\"./train\", exist_ok=True)\n",
    "\n",
    "    # 画像フォルダ指定\n",
    "    image_dir = dirdialog_clicked()\n",
    "    img_lists = os.listdir(path=image_dir)\n",
    "\n",
    "    for lists in range(len(img_lists)):\n",
    "        in_dir = image_dir +\"/\"+img_lists[lists] + \"/*\"\n",
    "        out_dir = \"./train/\" + img_lists[lists]+\"/\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        in_jpg=glob.glob(in_dir)\n",
    "        save_num=0\n",
    "        for i in in_jpg:\n",
    "            img = imread(i)\n",
    "            # 左右反転\n",
    "\n",
    "            img_flip = cv2.flip(img, 1)\n",
    "            fileName = os.path.join(out_dir, str(save_num) + \"_flip.jpg\")\n",
    "            imwrite(str(fileName), img_flip)\n",
    "            # 回転\n",
    "            for ang in [-10,0,10]:\n",
    "                img_rot = ndimage.rotate(img,ang)\n",
    "                img_rot = cv2.resize(img_rot,(64,64))\n",
    "                fileName=os.path.join(out_dir,str(save_num)+\"_\"+str(ang)+\".jpg\")\n",
    "                imwrite(str(fileName),img_rot)\n",
    "                # 閾値\n",
    "                img_thr = cv2.threshold(img_rot, 100, 255, cv2.THRESH_TOZERO)[1]\n",
    "                fileName=os.path.join(out_dir,str(save_num)+\"_\"+str(ang)+\"thr.jpg\")\n",
    "                imwrite(str(fileName),img_thr)\n",
    "                # ぼかし\n",
    "                img_filter = cv2.GaussianBlur(img_rot, (5, 5), 0)\n",
    "                fileName=os.path.join(out_dir,str(save_num)+\"_\"+str(ang)+\"filter.jpg\")\n",
    "                imwrite(str(fileName),img_filter)\n",
    "            save_num += 1\n",
    "```\n",
    "![水増し後](./4.png)\n",
    "こんな感じになります。  \n",
    "  \n",
    "それぞれ1000～2000枚くらいの教師データがtrainフォルダに保存されました。 \n",
    "  \n",
    "ただ、人物によってかなり枚数に差が出てしまうのは学習にどんな影響を及ぼしているかわからないので不安です。改善するべきかも？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "これ以前のコード変更に加えて、分類するクラス数（人数）を好きにできるように書き換えました。  \n",
    "また、モデルの保存一番最後にしていたために、学習終わって精度のグラフのプロットでエラーが出て、十数分無駄にしてしまったので、モデルの保存を学習した直後にするようにしました。\n",
    "\n",
    "しかしその辺りは勉強不足なので、クラス数を増やしすぎたりするのは良くなさそうだと思いました。  \n",
    "  \n",
    "  \n",
    "フォルダ選択は、教師データが入っているフォルダ（今回はtrain）を選択します。\n",
    "\n",
    "  \n",
    "``` python:learn.py\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "\n",
    "image_dir = dirdialog_clicked()\n",
    "name = os.listdir(path=image_dir)\n",
    "\n",
    "# パスに日本語が含まれる場合の対策\n",
    "# np.profileとcv2.imdecodeに分解した\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "#cv2.imencode + np.ndarray.tofile に分解\n",
    "def imwrite(filename, img, params=None):\n",
    "    try:\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        result, n = cv2.imencode(ext, img, params)\n",
    "\n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f:\n",
    "                n.tofile(f)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "# 教師データのラベル付け\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(len(name)):\n",
    "    img_file_name_list=os.listdir(\"./train/\"+name[i])\n",
    "    print(len(img_file_name_list))\n",
    "    for j in range(0,len(img_file_name_list)-1):\n",
    "        n=os.path.join(\"./train/\"+name[i]+\"/\",img_file_name_list[j])\n",
    "        img = imread(n)\n",
    "        b,g,r = cv2.split(img)\n",
    "        img = cv2.merge([r,g,b])\n",
    "        X_train.append(img)\n",
    "        Y_train.append(i)\n",
    "\n",
    "# テストデータのラベル付け\n",
    "X_test = [] # 画像データ読み込み\n",
    "Y_test = [] # ラベル（名前）\n",
    "for i in range(len(name)):\n",
    "    img_file_name_list=os.listdir(\"./test/\"+name[i])\n",
    "    print(len(img_file_name_list))\n",
    "    for j in range(0,len(img_file_name_list)-1):\n",
    "        n=os.path.join(\"./test/\"+name[i]+\"/\",img_file_name_list[j])\n",
    "        img = imread(n)\n",
    "        b,g,r = cv2.split(img)\n",
    "        img = cv2.merge([r,g,b])\n",
    "        X_test.append(img)\n",
    "        # ラベルは整数値\n",
    "        Y_test.append(i)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(64, 64, 3), filters=32,kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(len(name))) # 人数決めるところ\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=32,\n",
    "                    epochs=50, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "#モデルを保存\n",
    "model.save(\"my_model.h5\")\n",
    "\n",
    "# 汎化制度の評価・表示\n",
    "score = model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
    "print('validation loss:{0[0]}\\nvalidation accuracy:{0[1]}'.format(score))\n",
    "\n",
    "#acc, val_accのプロット\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\", ls=\"-\", marker=\"o\")\n",
    "print(\"1\")\n",
    "print(history.history)\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\", ls=\"-\", marker=\"x\")\n",
    "print(history.history)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "```\n",
    "![学習結果](./5.png)\n",
    "青いほうが教師データと比較したときの精度、オレンジ色のほうが、テストデータと比較したときの精度です。  \n",
    "青は、学習に使ったデータとそこからできたモデルを比較してるので、正しく学習できていればオレンジより高くなっているはずです。  \n",
    "  \n",
    "  \n",
    "結果としては、わりといい感じになったと思います  \n",
    "  \n",
    "層を増やしたりepoch数を増やしても、精度は大体0.8くらいで落ち着いたので、ここからさらに上げるにはどうすればいいのかいろいろ試してみたいです。  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テスト\n",
    "学習したモデルを使用して実際に分類してみます。  \n",
    "  \n",
    "フォルダ名をもとに分類した後のクラス名を指定したので、例のごとくopencvの関数でいくつかエラーが出、その対策を行いました。  \n",
    "日本語だとcv2.putTextが使用できず、PILのdraw.textで代用した部分は結構頑張りました。  \n",
    "\n",
    "  \n",
    "  \n",
    "実行すると、GUIでファイル選択を求められるので、分類したい人物の顔が映った画像を選択します。\n",
    "  \n",
    "```python:predict.py\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir=iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "\n",
    "def select_image():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    fTyp = [(\"\", \"*\")]\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    filePath = filedialog.askopenfilename(filetypes=fTyp, initialdir=iDir)\n",
    "    root.destroy()\n",
    "    return filePath\n",
    "\n",
    "\n",
    "# パスに日本語が含まれる場合の対策\n",
    "# np.profileとcv2.imdecodeに分解した\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "# cv2.imencode + np.ndarray.tofile に分解\n",
    "def imwrite(filename, img, params=None):\n",
    "    try:\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        result, n = cv2.imencode(ext, img, params)\n",
    "\n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f:\n",
    "                n.tofile(f)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "def puttext(cv_image, text, point, font_path, font_size, color=(0, 0, 0)):\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    cv_rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(cv_rgb_image)\n",
    "\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    #draw.text(point, text, fill=color, font=font)\n",
    "    draw.text(point, text, fill=color, font=font)\n",
    "\n",
    "    cv_rgb_result_image = np.asarray(pil_image)\n",
    "    cv_bgr_result_image = cv2.cvtColor(cv_rgb_result_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return cv_bgr_result_image\n",
    "\n",
    "\n",
    "def detect_face(image):\n",
    "    # opencvを使って顔抽出\n",
    "    image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_alt.xml\")\n",
    "    # 顔認識の実行\n",
    "    face_list = cascade.detectMultiScale(image_gs, scaleFactor=1.1, minNeighbors=2, minSize=(64, 64))\n",
    "    # 顔が１つ以上検出された時\n",
    "    if len(face_list) > 0:\n",
    "        for rect in face_list:\n",
    "            x, y, width, height = rect\n",
    "            cv2.rectangle(image, tuple(rect[0:2]), tuple(rect[0:2] + rect[2:4]), (255, 0, 0), thickness=3)\n",
    "            img = image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]\n",
    "            if image.shape[0] < 64:\n",
    "                print(\"too small\")\n",
    "                continue\n",
    "            img = cv2.resize(image, (64, 64))\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            name = detect_who(img)\n",
    "            fontpath = 'C:\\Windows\\Fonts\\meiryo.ttc'\n",
    "            image = puttext(image, name, (x, y + height + 20), fontpath, 24, (255, 0, 0))\n",
    "            #cv2.putText(image, name, (x, y + height + 20), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 2)\n",
    "    # 顔が検出されなかった時\n",
    "    else:\n",
    "        print(\"no face\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def detect_who(img):\n",
    "    # image_dir = dirdialog_clicked()\n",
    "    # name_list = os.listdir(path=image_dir)\n",
    "    name_list = os.listdir(path=\"./face\")\n",
    "    # 予測\n",
    "    name = \"\"\n",
    "    print(model.predict(img))\n",
    "    print(name_list)\n",
    "    nameNumLabel = np.argmax(model.predict(img))\n",
    "    print(nameNumLabel)\n",
    "    for num in range(len(name_list)):\n",
    "        if nameNumLabel == num:\n",
    "            name = name_list[num]\n",
    "            print(name,name_list[num])\n",
    "    return name\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = load_model('./my_model.h5')\n",
    "    image = imread(select_image())\n",
    "    if image is None:\n",
    "        print(\"Not open:\")\n",
    "    whoImage = detect_face(image)\n",
    "\n",
    "    cv2.imshow(\"result\", whoImage)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "```\n",
    "こういった感じになりました。\n",
    "![分類結果](./6.png)  \n",
    "\n",
    "フォルダ名から情報をとってくるので、faceフォルダが存在しないと動かなくなってしまいます。  txtとか、csvなんかに情報だけおいとくように改善できるなと思いました。  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感想\n",
    "始めてDeepLeerningをやってみましたが、ちゃんと分類できて驚きました。この前に、カスケード分類器を自作して顔検出することに挑戦したのですが、その際はかなり精度が悪かったので、この結果はかなり感動しました。  \n",
    "コードは参考記事のものを参考にしましたが、やはり少しでも書き換えようとすると、コードの大部分の理解が必要になってくるので、かなり勉強にはなったと思います。  \n",
    "\n",
    "自分流にしたことによって生じた不都合な部分も多々あるので、今後に生かせると感じました。\n",
    "  \n",
    "    \n",
    "    \n",
    "ディープラーニングについても理解できた部分はあると思うのですが、まだまだ不十分さを感じたので、これ以降の制作の際にまとめるつもりです。\n",
    "  \n",
    "このようにマークダウンを使ってまとめを作るのも初挑戦で、書き方すら参考記事を参考にしてしまった感がありますが、あとで見返すにも、CNNやろうとしてる友人にひけらかすにもとても便利だと感じたので、極力これからも書いていければと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
