{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNを用いた坂道グループのメンバーの顔分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングをやりたくて、さわりとしてCNNを使った顔分類をやろうと思いました。  \n",
    "  \n",
    "乃木坂メンバーの顔をCNNで分類  \n",
    "https://qiita.com/nirs_kd56/items/bc78bf2c3164a6da1ded2    \n",
    "いろいろなサイトを見た結果、こちらのサイトが丁寧でわかりやすかったのでかなり参考にさせてもらいました。  \n",
    "  \n",
    "テーマが似たような感じなのはたまたま趣味が同じだったってことで、ここを変えたとこで差別化はできないと思ったのでこんなかんじになりました。  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境\n",
    "あとで書く！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！\n",
    "## 手順\n",
    "最後に書く！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像のスクレイピング\n",
    "参考記事のスクレイピングは、chromeの仕様変更に伴って使えなくなっていたようなので、一から作り直しました。 \n",
    "  \n",
    "画像読み込みがページ切り替えで分かりやすかったYahoo画像検索を使用しました。  \n",
    "一度の実行で学習させたい人数分を一度にスクレイピングすることが出来ます。  \n",
    "  \n",
    "  \n",
    "検索結果画面のサムネイルを保存しているような形なので、画像サイズがかなり小さくなっていますが、一応使えます。\n",
    "``` python:image_collect.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import time\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "def main(search_word,maxcount):\n",
    "    # 検索URL準備\n",
    "    load_url=\"https://search.yahoo.co.jp/image/search?p=\"+search_word+\"&ei=UTF-8&b=\"\n",
    "\n",
    "\n",
    "    # 保存用フォルダを作る\n",
    "    data = Path(\"./data\")\n",
    "    data.mkdir(exist_ok=True)\n",
    "    out_folder=Path(\"data/\"+search_word)\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # すべてのhtmlタグを検索し、リンクを取得する\n",
    "    count=1\n",
    "\n",
    "    for i in range(1,maxcount,20):\n",
    "\n",
    "        # ページ切り替え\n",
    "        html = requests.get(load_url+str(i))\n",
    "        soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "        for element in soup.find_all(\"img\"):\n",
    "            src=element.get(\"src\")\n",
    "\n",
    "            # 絶対URLから画像を取得する\n",
    "            image_url=urllib.parse.urljoin(load_url,src)\n",
    "            imgdata=requests.get(image_url)\n",
    "\n",
    "            # URLから最後のファイル名を取り出して保存先のファイル名とつなげる\n",
    "            filename=str(count)+\".png\"\n",
    "            out_path=out_folder.joinpath(filename)\n",
    "\n",
    "            # 画像データをファイルに書き出す\n",
    "            with open(out_path,mode=\"wb\") as f:\n",
    "                f.write(imgdata.content)\n",
    "\n",
    "            # 枚数が十分だったらやめる\n",
    "            if maxcount<=count:\n",
    "                print(search_word+\"完了\")\n",
    "                break\n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "\n",
    "            # 0.2秒待つ\n",
    "            time.sleep(0.2)\n",
    "        print(str(count) + \"枚取得\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    member = []\n",
    "    num = int(input(\"人数\"))\n",
    "    for i in range(num):\n",
    "        member.append(input(\"検索ワード\"))\n",
    "    b = int(input(\"取得枚数\"))\n",
    "    for i in range(len(member)):\n",
    "        main(member[i], b)\n",
    "```\n",
    "  \n",
    "このコードを実行すると、標準入力が求められるので\n",
    "1. 人数\n",
    "2. 検索ワード(×人数)\n",
    "3. 取得枚数  \n",
    "![入力したときの感じ](./1.png)\n",
    "\n",
    "\n",
    "↑のように入力していきます。  \n",
    "  \n",
    "スクレイピングした画像はおなじ階層に以下のようなフォルダ構成で保存されます。\n",
    ">data/  \n",
    ">├ 検索ワード1/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  \n",
    ">  │　       \n",
    ">├ 検索ワード2/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  　       \n",
    ">...\n",
    "  \n",
    "600～700枚が限界みたいです。  \n",
    "実際200～300枚で十分学習はできるうえ、画像が多いとこの後の作業がだいぶきつくなるのでほどほどにしておきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顔部分のトリミング\n",
    "参考記事のコードを少し変えました。  \n",
    "  \n",
    "  \n",
    "スクレイピングで作成されるフォルダ名に、検索ワードがそのまま使われるようになっているので、日本語のパスだとエラーが出るopencvの関数の対策などをしました。  \n",
    "  \n",
    "また、人数分コードを変えてトリミングするのも面倒なので、Tkinterを使用してGUIでフォルダを指定し、画像フォルダがまとめて保存されているフォルダ（今回はdataフォルダ）を選択すればすべてにトリミングが適用されるようにしました。  \n",
    "この変更はここから学習のコードまですべてにしています。\n",
    "  \n",
    "  \n",
    "このへんもパス関連で不具合が多く、Jupyterではうまく動かないというところが解決できませんでした。\n",
    "``` python:face_detect.py\n",
    "import glob\n",
    "import os\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "dataディレクトリから画像を読み込んで顔を切り取ってfaceディレクトリに保存.\n",
    "\"\"\"\n",
    "out_dir = \"./face\"\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "\n",
    "# パスに日本語が含まれる場合の対策\n",
    "# np.profileとcv2.imdecodeに分解した\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "#cv2.imencode + np.ndarray.tofile に分解\n",
    "def imwrite(filename, img, params=None):\n",
    "    try:\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        result, n = cv2.imencode(ext, img, params)\n",
    "\n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f:\n",
    "                n.tofile(f)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #各フォルダ指定\n",
    "    image_dir = dirdialog_clicked()\n",
    "    img_lists=os.listdir(path=image_dir)\n",
    "    out_dir=\".\"\n",
    "\n",
    "    for lists in range(len(img_lists)):\n",
    "        # 元画像を取り出して顔部分を正方形で囲み、64×64pにリサイズ、別のファイルにどんどん入れてく\n",
    "        in_dir = image_dir +\"/\"+img_lists[lists] + \"/*.png\"\n",
    "        print(in_dir)\n",
    "        in_jpg = glob.glob(in_dir)\n",
    "        print(in_jpg)\n",
    "        os.makedirs(\"./face/\"+ os.path.basename(img_lists[lists]), exist_ok=True)\n",
    "        for num in range(len(in_jpg)):\n",
    "            image = imread(image_dir +\"/\"+img_lists[lists]+\"/\"+str(num+1)+\".png\")\n",
    "            print(image_dir +\"/\"+img_lists[lists]+\"/\"+str(num+1)+\".png\")\n",
    "            if image is None:\n",
    "                print(\"Not open:\", num)\n",
    "                continue\n",
    "\n",
    "            image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_alt.xml\")\n",
    "            # 顔認識の実行\n",
    "            face_list = cascade.detectMultiScale(image_gs, scaleFactor=1.1, minNeighbors=2, minSize=(64, 64))\n",
    "            # 顔が１つ以上検出された時\n",
    "            if len(face_list) > 0:\n",
    "                for rect in face_list:\n",
    "                    x, y, width, height = rect\n",
    "                    image = image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]]\n",
    "                    if image.shape[0] < 64:\n",
    "                        continue\n",
    "                    image = cv2.resize(image, (64, 64))\n",
    "                    # 保存\n",
    "                    fileName = \"./face/\"+ os.path.basename(img_lists[lists])+\"/\"+str(num) + \".png\"\n",
    "                    imwrite(str(fileName), image)\n",
    "                    print(fileName)\n",
    "                    print(str(num) + \".pngを保存しました.\")\n",
    "            # 顔が検出されなかった時\n",
    "            else:\n",
    "                print(\"no face\")\n",
    "                continue\n",
    "            print(image.shape)\n",
    "\n",
    "``` \n",
    "スクレイピングした画像はおなじ階層に以下のようなフォルダ構成で保存されます。\n",
    ">face/  \n",
    ">├ 検索ワード1/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  \n",
    ">  │　       \n",
    ">├ 検索ワード2/  \n",
    ">  │　       　　├ 1.png  \n",
    ">  │　       　　├ 2.png  \n",
    ">  │　       　　├ ...  　       \n",
    ">...\n",
    "  \n",
    "![顔認識したフォルダ](./2.png)\n",
    "こういった感じです。 \n",
    "  \n",
    "ここで手作業で、  \n",
    "\"分類したい人ではない画像\"、\"顔ではない部分の画像\"、\"学習に悪影響を及ぼしそうな画像\"  \n",
    "を消去していきます。（苦行）  \n",
    "  \n",
    "  \n",
    "700枚近くあった画像がこの時点で150～250枚程度まで減っています。  \n",
    "\n",
    "顔認識の時点でかなりの枚数が削られているので、スクレイピングの時点で高画質な画像を持ってこれるようにすれば改善するかもしれません。  \n",
    "それをするには画像それぞれのリンク先に飛ぶなりしてオリジナルの画像を持ってこる必要がありそうなので、いつか挑戦してみたいです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クロス・バリデーションのための画像仕分け\n",
    "クロス・バリデーションとは、データセット全体をk分割し、1つをテストデータ、残りを教師データとして学習を行うもの。\n",
    "  \n",
    "それをするために画像を一定の割合でランダムにフォルダ分けするコードです。\n",
    "  \n",
    "  \n",
    "こちらも、日本語パス対策とGUIでのフォルダ指定ができるようにしています。\n",
    "  \n",
    "顔をトリミングした画像フォルダがあるフォルダを指定します。（今回はfaceフォルダ）\n",
    "``` python:.py\n",
    "# 2割をテストデータに移行\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "os.makedirs(\"../test\", exist_ok=True)\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 画像フォルダ指定\n",
    "    image_dir = dirdialog_clicked()\n",
    "    img_lists = os.listdir(path=image_dir)\n",
    "    for lists in range(len(img_lists)):\n",
    "        in_dir = image_dir +\"/\"+img_lists[lists]+\"/*\"\n",
    "        in_jpg=glob.glob(in_dir)\n",
    "        img_file_name_list=os.listdir(image_dir +\"/\"+img_lists[lists]+\"/\")\n",
    "        #img_file_name_listをシャッフル、そのうち2割をtest_imageディテクトリに入れる\n",
    "        random.shuffle(in_jpg)\n",
    "        os.makedirs('./test/' + os.path.basename(img_lists[lists]), exist_ok=True)\n",
    "        for t in range(len(in_jpg)//5):\n",
    "            shutil.move(str(in_jpg[t]), \"./test/\"+ os.path.basename(img_lists[lists]))\n",
    "``` \n",
    "これはデータセット全体を5分割し、うち1つをtestフォルダに送るものです。  \n",
    "成功すると、画像の8割がfaceフォルダに残り、2割がtestフォルダに送られています。\n",
    "![faceとtest](./3.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データの水増し\n",
    "ほかのコードと同じ変更に加えて、水増しのための画像加工に\"左右反転\"も加えました。  \n",
    "\n",
    "参考記事では、人の顔を左右反転するのもなあ、といった感じで反転はしないこととしていましたが、アイドルの自撮り画像は使用してるアプリの影響で左右反転されてるものも少なからずあるのと、教師データをめちゃくちゃに増やしてみたいという野望があったのでぼくは反転を取り入れることにしました。  \n",
    "\n",
    "なので、回転（3）×(オリジナル、ぼかし、閾値処理)＋反転で教師データが10倍になります。  \n",
    "  \n",
    "  \n",
    "コードを実行する際は、教師データが入って\n",
    "  \n",
    "``` python:inflation.py\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "faceディレクトリから画像を読み込んで回転、ぼかし、閾値処理をしてtrainディレクトリに保存する.\n",
    "\"\"\"\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "# パスに日本語が含まれる場合の対策\n",
    "# np.profileとcv2.imdecodeに分解した\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "#cv2.imencode + np.ndarray.tofile に分解\n",
    "def imwrite(filename, img, params=None):\n",
    "    try:\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        result, n = cv2.imencode(ext, img, params)\n",
    "\n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f:\n",
    "                n.tofile(f)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(\"./train\", exist_ok=True)\n",
    "\n",
    "    # 画像フォルダ指定\n",
    "    image_dir = dirdialog_clicked()\n",
    "    img_lists = os.listdir(path=image_dir)\n",
    "\n",
    "    for lists in range(len(img_lists)):\n",
    "        in_dir = image_dir +\"/\"+img_lists[lists] + \"/*\"\n",
    "        out_dir = \"./train/\" + img_lists[lists]+\"/\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        in_jpg=glob.glob(in_dir)\n",
    "        for i in range(len(in_jpg)):\n",
    "            img = imread(str(in_jpg[i]))\n",
    "            # 左右反転\n",
    "\n",
    "            img_flip = cv2.flip(img, 1)\n",
    "            fileName = os.path.join(out_dir, str(i) + \"_flip.jpg\")\n",
    "            imwrite(str(fileName), img_flip)\n",
    "            # 回転\n",
    "            for ang in [-10,0,10]:\n",
    "                img_rot = ndimage.rotate(img,ang)\n",
    "                img_rot = cv2.resize(img_rot,(64,64))\n",
    "                fileName=os.path.join(out_dir,str(i)+\"_\"+str(ang)+\".jpg\")\n",
    "                imwrite(str(fileName),img_rot)\n",
    "                # 閾値\n",
    "                img_thr = cv2.threshold(img_rot, 100, 255, cv2.THRESH_TOZERO)[1]\n",
    "                fileName=os.path.join(out_dir,str(i)+\"_\"+str(ang)+\"thr.jpg\")\n",
    "                imwrite(str(fileName),img_thr)\n",
    "                # ぼかし\n",
    "                img_filter = cv2.GaussianBlur(img_rot, (5, 5), 0)\n",
    "                fileName=os.path.join(out_dir,str(i)+\"_\"+str(ang)+\"filter.jpg\")\n",
    "                imwrite(str(fileName),img_filter)\n",
    "```\n",
    "![水増し後](./4.png)\n",
    "こんな感じになります。  \n",
    "  \n",
    "それぞれ1000～2000枚くらいの教師データがtrainフォルダに保存されました。 \n",
    "  \n",
    "ただ、人物によってかなり枚数に差が出てしまうのは学習にどんな影響を及ぼすのかわからないので不安です。改善するべきかも？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "これ以前のコード変更に加えて、分類するクラス数（人数）を好きにできるように書き換えました。  \n",
    "\n",
    "しかしその辺りは勉強不足なので、クラス数を増やしすぎたりするのは良くなさそうだと思いました。  \n",
    "  \n",
    "  \n",
    "フォルダ選択は、教師データが入っているフォルダ（今回はtrain）を選択します。\n",
    "\n",
    "  \n",
    "``` python:learn.py\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "\n",
    "# フォルダ指定\n",
    "def dirdialog_clicked():\n",
    "    root = tkinter.Tk()\n",
    "    root.withdraw()\n",
    "    iDir = os.path.abspath(os.path.dirname(__file__))\n",
    "    iDirPath = filedialog.askdirectory(initialdir = iDir)\n",
    "    root.destroy()\n",
    "    return iDirPath\n",
    "\n",
    "\n",
    "image_dir = dirdialog_clicked()\n",
    "name = os.listdir(path=image_dir)\n",
    "#name = [\"星野みなみ\",\"齋藤飛鳥\",\"松田好花\",\"nanami\",\"ikuta\"]\n",
    "\n",
    "# パスに日本語が含まれる場合の対策\n",
    "# np.profileとcv2.imdecodeに分解した\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8):\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)\n",
    "        img = cv2.imdecode(n, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "#cv2.imencode + np.ndarray.tofile に分解\n",
    "def imwrite(filename, img, params=None):\n",
    "    try:\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        result, n = cv2.imencode(ext, img, params)\n",
    "\n",
    "        if result:\n",
    "            with open(filename, mode='w+b') as f:\n",
    "                n.tofile(f)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "# 教師データのラベル付け\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(len(name)):\n",
    "    img_file_name_list=os.listdir(\"./train/\"+name[i])\n",
    "    print(len(img_file_name_list))\n",
    "    for j in range(0,len(img_file_name_list)-1):\n",
    "        n=os.path.join(\"./train/\"+name[i]+\"/\",img_file_name_list[j])\n",
    "        img = imread(n)\n",
    "        b,g,r = cv2.split(img)\n",
    "        img = cv2.merge([r,g,b])\n",
    "        X_train.append(img)\n",
    "        Y_train.append(i)\n",
    "\n",
    "# テストデータのラベル付け\n",
    "X_test = [] # 画像データ読み込み\n",
    "Y_test = [] # ラベル（名前）\n",
    "for i in range(len(name)):\n",
    "    img_file_name_list=os.listdir(\"./test/\"+name[i])\n",
    "    print(len(img_file_name_list))\n",
    "    for j in range(0,len(img_file_name_list)-1):\n",
    "        n=os.path.join(\"./test/\"+name[i]+\"/\",img_file_name_list[j])\n",
    "        img = imread(n)\n",
    "        b,g,r = cv2.split(img)\n",
    "        img = cv2.merge([r,g,b])\n",
    "        X_test.append(img)\n",
    "        # ラベルは整数値\n",
    "        Y_test.append(i)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(64, 64, 3), filters=32,kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(len(name))) # 人数決めるところ\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=32,\n",
    "                    epochs=50, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# 汎化制度の評価・表示\n",
    "score = model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
    "print('validation loss:{0[0]}\\nvalidation accuracy:{0[1]}'.format(score))\n",
    "\n",
    "#acc, val_accのプロット\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\", ls=\"-\", marker=\"o\")\n",
    "print(\"1\")\n",
    "print(history.history)\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\", ls=\"-\", marker=\"x\")\n",
    "print(history.history)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "#モデルを保存\n",
    "model.save(\"my_model.h5\")\n",
    "```\n",
    "![学習結果](./5.png)\n",
    "青いほうが教師データと比較したときの精度、オレンジ色のほうが、テストデータと比較したときの精度です。  \n",
    "青は、学習に使ったデータとそこからできたモデルを比較してるので、正しく学習できていればオレンジより高くなっているはずです。  \n",
    "  \n",
    "  \n",
    "結果としては、わりといい感じになったと思います  \n",
    "  \n",
    "層を増やしたりepoch数を増やしても、精度は大体0.8くらいで落ち着いたので、ここからさらに精度を上げるにはどうすればいいのかいろいろ試してみたいです。\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
